# -*- coding: utf-8 -*-
"""Churn DE BADIBENGI_GOURDET.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/142UpnOZ_ebbKdFcn45C80r16NYOPs74R

# **Churn**
> ### **Objectif**
> L'objectif de churn est de prédire, à l'aide des éléments contenus dans la base de données, si un client va quitter l'entreprise. Nous sommes donc dans une problématique d'apprentissage supervisé de type régression logistique. En effet, nous pouvons déterminer deux types de variables, expliquée et explicative. Ici la variable expliquée est "churn" et les variables explicatives sont toutes les autres, qui peuvent être considérées comme des facteurs poussant le client à quitter l'entreprise.

### **Chargement des données**
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn import tree
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import pandas as pd
import numpy as np

df = pd.read_csv("https://assets-datascientest.s3-eu-west-1.amazonaws.com/de/total/churn.csv", index_col="customerID")

df.head(10)

"""## **1.   Premières observations**

> Dans un premier temps, nous pouvons observer que certaines variables tel que "SeniorCitizen" ont des valeurs égalent à 1 pour la classe positive et à 0 pour la classe négative. De plus, d'autres variables tels que "Partner", "Dependents", "PhoneService" "PaperlessBilling" et "churn" valent "Yes" ou "No", ainsi, nous pourrons remplacer ces valeurs par 1 et 0 (Yes et No). Des variables tels que "MultipleLines", "InternetService", "OnlineSecurity", "OnlineBackup", "DeviceProtection", "TechSupport", "StreamingTV" et "StreamingMovies" contiennent des valeurs qui peuvent également être remplacé par "Yes" ou "No" (ex: No internet service, No phone service, Fibre optic,DSL, etc.).

> Nous allons donc commencer par nettoyer nos données et remplacer les valeurs citées plus haut.

# 1.    Nettoyage de données

*   Détection des valeurs manquantes
"""

df.isna().sum()

#print("Il y a", df.isna().any().sum(), "valeur manquante")

"""> Aucune valeur manquante n'a été détectée.

*   Détection des valeurs abérrantes
"""

# On a fait la même chose pour toutes les autres colonnes

df.loc[(df["SeniorCitizen"] != 0 ) & (df["SeniorCitizen"] != 1)]
df.loc[(df["StreamingMovies"] != "Yes" ) & (df["StreamingMovies"] != "No") & (df["StreamingMovies"] != "No internet service")]

"""*   On remplace les valeurs "Yes", "No", "No internet service", "No phone service", "Femal", "Male", "Fiber optic" et "DSL" par 1 ou 0.

*   De plus, on s'interesse à la colonne "Contract" qui contient les valeurs "Two year", "Month-to-month", "One year". On décide donc de remplacer "Two year" par 730, car il y a 730 jours dans deux années, "Month-to-month" est remplacé par 30 jours et enfin, "One year" par 365 jours.
"""

#On remplace les valeurs "Yes", "No", "No internet service", "No phone service", "Femal", "Male", "Fiber optic" et "DSL" par 1 ou 0.
df = df.replace(to_replace = ["Yes", "No", "No internet service", "No phone service", "Female", "Male", "Fiber optic", "DSL"],
                   value=[1, 0, 0, 0,1,0,1,1])

#On remplace "Two year" par 730 et "Month-to-month" par 30
df = df.replace(to_replace=["Two year", "Month-to-month", "One year"], value=[730, 30, 365])


#On verifie que seul ces trois valeurs sont présentes dans cette colonne
df.loc[(df["Contract"] != 730 ) & (df["Contract"] != 30) & (df["Contract"] != 365)]

df.head()

"""
*  Pour la colonne "PaymentMethod" nous allons utiliser la technique de l'encodage one-hot, grâce à la fonction OneHotEncoder de sklearn.preprocessing. Cette fonction va donc nous permettre d'encoder les valeurs de cette colonne par 1 ou 0.

"""

df_new = df.copy()

transformer = make_column_transformer(
    (OneHotEncoder(), ['PaymentMethod']),
    remainder='passthrough')

transformed = transformer.fit_transform(df_new)
df_new = pd.DataFrame(transformed,columns=transformer.get_feature_names())

#On renomme le nom des nouvelles colonnes encodées
dico = {"onehotencoder__x0_Bank transfer (automatic)": "Bank transfer (automatic)",
        "onehotencoder__x0_Credit card (automatic)": "Credit card (automatic)",
        "onehotencoder__x0_Electronic check": "Electronic check",
        "onehotencoder__x0_Mailed check": "Mailed check"}
df_new = df_new.rename(dico, axis=1)

#On change le type des nouvelles colonnes
dico2 = {"Bank transfer (automatic)":"int",
         "Credit card (automatic)":"int",
         "Electronic check":"int",
         "Mailed check":"int"}
df_new = df_new.astype(dico2)

df_new.index = df.index
df_new.head(5)

"""

*   Les valeurs de la colonne "TotalCharges" ne sont pas toutes au même format. En effet, cette colonne est au format str et on y trouve des valeurs avec des points, ainsi que des valeurs sans points. Nous ne pouvons donc pas convertir cette colonne directement en utilisant une fonction telle que astype car cela nous génère une erreur. 

*   Nous allons donc convertir cette colonne au format numérique en utilisant "to_numeric".



"""

y = df_new

y = pd.to_numeric(y["TotalCharges"], errors='coerce')
df_new["TotalCharges"] = y

#On verifie encore une fois s'il y a des valeurs manquantes
df_new.isna().sum()

"""*   Nous pouvons remarquer que la colonne "TotalCharges" contient 10 valeurs manquantes.


"""

# On affiche les lignes avec des valeurs manquantes
df_new[df_new.isnull().any(axis=1)]

"""*   On remplace les valeurs manquantes de la colonne "TotalCharges" par sa mediane."""

#On remplace les valeurs manquantes par la valeur 0
df_new["TotalCharges"] = df_new["TotalCharges"].fillna(df_new["TotalCharges"].median())

#On affiche les lignes qui contiennent des valeurs manquantes
df_new[df_new.isnull().any(axis=1)]

"""# 1.   Analyse des données

> Nous allons observer le comportement de total charge, phoneservice, ainsi que d'autres variables pour voir comment elles se comportent en fonction de Churn.

*   Nous allons commencer par observer comment se comporte la variable "Churn" qui est la variable expliquée.
"""

plt.figure(figsize=(7,7))
plt.title("Valeurs de Churn")
plt.pie([df_new["Churn"].value_counts()[0], df_new["Churn"].value_counts()[1]],
        labels=["Non", "Oui"],
        colors=["red", "blue"],
        autopct=(lambda x: str(np.round(x,2)) + "%"),
        shadow=True)
plt.legend();

"""Nous observons donc qu'il y a 73,49% où churn vaut 0 (classe négative) et 26,51% lorsque churn vaut 1 (classe positive).

*   Afin de comprendre comment se comporte Churn avec les autres variables, nous allons créer des graphes en utilisant la librairie matplotlib, pour les comparer et essayer d'en tirer une première conclusion avant d'utiliser les algorithmes de machine learning.
"""

#On utilise groupby pour grouper les élément du Dataframe entre gender et Churn, on utilise size pour avoir
#la valeur total d'élément entre gender et churn (lorsque churn vaut 0 ou 1 et pareil pour gender)

df_gender = df_new.groupby(['gender', 'Churn']).size().reset_index()
total = {0: "Total"}
df_gender = df_gender.rename(total, axis = 1)
df_gender["%"] = np.round(df_gender["Total"]/100, 2)

df_gender.head()

df_gender.plot.bar(x="Churn", y='Total', color = ["salmon", "aquamarine"],
                   title= "Churn en fonction de gender",
                   ylabel="Total");

"""Les deux premiers graphes (à gauche) représentent des hommes, et les deux derniers graphes (à droite) représentent des femmes. On peut constater cela, grâce à notre tableau qui regroupe "gender" et "Churn". En effet, on a deux états de "gender", ainsi nous remarquons qu'il y a 22,54% de personne qui résilient et 7,96% de personnes qui ne résilient pas lorsque ce sont des hommes. 

Nous suivons le même raisonnement pour les femmes, et nous remarquons qu'il y a 21,45% de personnes qui résilient et que seulement 7,91% de personnes de résilient pas lorsque ce sont des femmes.

*   Nous allons nous intéresser aux différents modes de payment, et observer le nombre de départ selon les moyens de payements.
"""

#On commence par créer une fonction pour simplifier l'affichage de nos graphiques

def display(a, my_df):
  data = my_df.groupby([a, "Churn"]).size().reset_index()
  total = {0: "Total"}
  data = data.rename(total, axis = 1)
  data["%"] = np.round(data["Total"]/100, 2)

  graph = data.plot.bar(x="Churn", y='Total', color = ["salmon", "aquamarine"],
                   title= "Churn en fonction de" + " " +  a,
                   ylabel="Total");

  return (data)

display('Bank transfer (automatic)', df_new)

"""Nous remarquons que lorsque le payement ne se fait pas via Bank transfer, il y a 33,15% de personnes qui ne résilient pas et 13,63% résilient. Lorsque le payement se fait via Bank transfer, 10,84% de personnes ne résilient pas et 2,24% des personnes résilient. """

display('Credit card (automatic)', df_new)

"""Nous remarquons que lorsque le payement ne se fait pas via une carte de credit de manière automatique, il y a 32,94% de personnes qui ne résilient pas et 13,89% qui résilient. Lorsque le payement se fait via une carte de credit automatique, 11,05% de personnes ne résilient pas et 1,98% des personnes résilient. """

display('Electronic check', df_new)

"""Nous remarquons que lorsque le payement ne se fait pas via electronic check, il y a 32,95% des personnes qui ne résilient pas et 6.85% résilient. Lorsque le payement se fait via electronic check, 11,04% de personnes ne résilient pas et 9,02% des personnes résilient. """

display("Mailed check", df_new)

"""Nous remarquons que lorsque le payement ne se fait pas via Mailed check, il y a 32,93% de personnes qui ne résilient pas et 13,24% qui résilient. Lorsque le payement se fait via Mailed check, 11,06% de personnes ne résilient pas et 2,63% des personnes résilient.

*   On s'interesse également à PhoneService afin de voir comment se comporte cette variables en fonction de Churn.
"""

display("PhoneService", df_new)

"""Nous remarquons que lorsque le payement ne se fait pas via un service télephonique, il y a 4,41% de personnes qui ne résilient pas et 1.49% qui résilient. Lorsque le payement se fait via un service télephonique, 39,58% de personnes ne résilient pas et 14,38% des personnes résilient.

*   Afin d'obsever les données contenues dans "TotalCharges" et dans "MonthlyCharges", nous allons créer un nouveau Dataframe où les charges totales supérieures à 3000 euros vaudront 1 et les charges totales inférieures à 3000 euros vaudront 0. Nous faisons de même pour les charges mensuelles, où les charges supérieures à 1OO euros vaudront 1 et les charges inférieures vaudront 0.
"""

df_charge = df_new.copy()

#On remplace les valeurs de "TotalCharges" supérieures a 1000 euros à 1 et les valeurs inférieures à 0
b1 = np.where(df_new["TotalCharges"] >= 3000, 1, df_new["TotalCharges"])
b0 = np.where(b1 != 1, 0, b1)
df_charge["TotalCharges"] = b0

#On remplace les valeurs de "MonthlyCharges" supérieures a 100 euros à 1 et les valeurs inférieures à 0
m1 = np.where(df_new["MonthlyCharges"] >= 100, 1, df_new["MonthlyCharges"])
m0 = np.where(m1 != 1, 0, m1)
df_charge["MonthlyCharges"] = m0


df_charge.head()

display("TotalCharges",df_charge)

"""Nous remarquons que lorsque les charges totales sont inférieures à 3000 euros, il y a 28,16% de personnes qui ne résilient pas et 12,85% qui résilient. Lorsque les charges totales sont supérieures à 3000 euros, 15,83% de personnes ne résilient pas et 3,02% des personnes résilient. 


"""

display("MonthlyCharges",df_charge)

"""Nous remarquons que lorsque les charges mensuelles sont inférieures à 100 euros, il y a 38,51% de personnes qui ne résilient pas et 13.64% qui résilient. Lorsque les charges mensuelles sont supérieures à 100 euros, 5,488% de personnes ne résilient pas et 2,23% des personnes résilient. 


*   Cette observation est cohérante, car une personne qui paie plus est amenée à résilier son contrat pour payer moins.

# 2.   Application d'un algorithme de Régression Logistique
"""

df_new.head(5)

#Séparation des données 

from sklearn.model_selection import train_test_split 

X = df_new.drop(["Churn"], axis = 1)

y = df_new["Churn"]
y=y.astype('int')
# https://stackoverflow.com/questions/45346550/valueerror-unknown-label-type-unknown

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42, stratify = y)

#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

#Classification non-linéaire: modèle des K-Nearest Neighbors 


from sklearn.neighbors import KNeighborsClassifier

# Instanciation du modèle
knn = KNeighborsClassifier(n_neighbors = 6)

# Entraînement du modèle sur le jeu d'entraînement
knn.fit(X_train, y_train)

# Prédiction sur les données de test
y_pred_test_knn = knn.predict(X_test)

# Affichage des 10 premières prédictions
#print(y_pred_test_knn[:10])
accuracy_knn = metrics.accuracy_score(y_test, y_pred_test_knn)

# On créer un decision tree de type Classifier car on est dans une problématique d'apprentissage supervisé de type régression logistique (classification)
clf = tree.DecisionTreeClassifier()

# On entraîne notre modèle
clf = clf.fit(X_train, y_train)

# On decide de faire une predicition pour notre variable test
y_pred_clf = clf.predict(X_test)
accuracy_clf = metrics.accuracy_score(y_test, y_pred_clf)
# On affiche l'accuracy de notre decision tree
#print("Accuracy:", metrics.accuracy_score(y_test, y_pred_clf))

#Entraînement du modèle 

# A partir du module linear_model de la librairie scikit learn on importe la fonction LogisticRegression

from sklearn.linear_model import LogisticRegression 
import numpy as np 
#On instancie le modèle et on l'entraîne 
model_log = LogisticRegression(solver="newton-cg").fit(X_train, y_train)

#On prédit les y à partir de X_test et X_train
y_pred = model_log.predict(X_test)

#On affiche les coefficients obtenus 
coeff = model_log.coef_
#On affiche la constance 
intercept = model_log.intercept_ 

#On calcule les odd ratios 
odd_ratios = np.exp(model_log.coef_)

#On crée un dataframe qui combine à la fois variables, oddrations et coefficients

resultats = pd.DataFrame(X.columns, columns=['Variables'])
resultats['Coefficients'] = model_log.coef_.tolist()[0]
resultats['Odd_Ratios'] = np.exp(model_log.coef_).tolist()[0]

#On choisit d'afficher les variables avec le coefficient le plus élevé et le plus faible 
resultats.loc[(resultats['Odd_Ratios']== max(resultats["Odd_Ratios"]))|(resultats['Odd_Ratios']== min(resultats["Odd_Ratios"]))]

# Interprétation 

# 1) Phone service: lorsque la variable PhoneService diminue de 1 (donc lorsque il n'y a pas de service téléphonique), cela diminue les chances d'appartenir à la classe positive (réabonnement) d'environ 3 fois.

# 2) PaperlessBilling: lorsque la variable PaperlessBilling augmente de 0.40 (donc lorque les factures sont dématérialisés), alors cela augmente d'environ 1 fois et demi les chances d'appartenir à la classe positive (réabonnement)

"""* On compare nos résultat avec les graphiques que nous avions obtenu pour "Bank transfer", "Credit card", "Electronic check", "Mailed check", "gender" et "PhoneService"  


"""

resultats.head(22)

"""* "Bank transfer" et "Credit card" on un odd-ratio de 0.8 et un coefficien de -0.1, on calcul donc l'inverse du odd-ratio et on obtient 1.25. Ce qui veut dire que lorsque le paiement via "Bank transfer" ou via "Credit card" augmente de 1 alors cela diminue les chances de 25% de résilier. Cela est cohérent avec notre graphique, car il y seulement 2.24% de personnes qui résilient contre 10.84% qui font le contraire pour le paiement via "Bank transfer". 

* "Electronic check" a un odd-ratio de 1.36 et un coefficient de 0.3. Ce qui veut dire que lorsque le paiement se fait via "Electronic check", alors les chances qu'il a de résilier augmentent de 36%.

* "Mailed check" a un coefficient de 0.003350	et un odd-ratio de 1.0033. ce qui veut dire que lorsque le paiement ce fait via "Mailed check", alors les chances qu'il a de résilier augmentent de 0.33%. 

* "gender" a un coefficient de 0.0587	et un odd-ratio de 1.0605. ce qui veut dire que lorsque c'est une femme, alors les chances qu'elle a de résilier augmentent de 6%.

* "PhoneService" a un coefficient de -1.05 et un odd-ratio de	0.35, on calcul donc l'inverse du odd-ratio et on obtient 2.86. Ce qui veut dire que lorsque le service telephonique augment de 2 alors cela diminu les chances de 86% de résilier.


> Nos résultats sont assez cohérents avec les observations que nous avions faites via nos graphes.

Nous venons donc au sein des étapes précédentes :

D'importer notre jeu de données: variables explicatives (X) et la variable cible (y);
De séparer la base de données en une partie train et une partie test en respectant la proportion de chaque classe au sein de la base ;
D'entraîner le modèle de régression logistique sur nos données d'entraînement;
De prédire les classes de la variable cible y à partir des coefficients estimés du modèle;
De calculer les odd ratios à partir des coeficients estimés par le modèle, pour interpréter leur impact sur la variable cible.
Il reste ainsi à calculer les performances de notre modèle, pour cela nous allons utiliser la prédiction de y ainsi que des métriques adaptées au problème de classification, c'est ce que nous allons voir dans la partie suivante.

# 3. Mesure de performance : Les métriques ¶
"""

#Matrice de confusion 

from sklearn.metrics import confusion_matrix

# Insérez votre code

confusion_matrix(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
#print("\n Vrais négatifs:",tn,"\n Faux positifs:",fp,"\n Faux négatifs:",fn,"\n Vrais positifs:",tp)

#Accuracy score 

from sklearn.metrics import accuracy_score

#print("Accuracy score: " ,accuracy_score(y_test, y_pred))
accuracy_lr = accuracy_score(y_test, y_pred)

# On importe la fonction balanced_accuracy_score du module metrics de la librairie Scikit Learn

from sklearn.metrics import balanced_accuracy_score

# On vérifie la répartition des classes

#print("Répartition des classes : \n",y.value_counts(),"\n")

# La classe négative est surreprésentée par rapport à la classe 1.

# On affiche la balanced accuracy du modèle 

#print("Balanced accuracy:",balanced_accuracy_score(y_test,y_pred))
balance_accuracy = balanced_accuracy_score(y_test,y_pred)

# Les résultats obtenus avec la balanced accuracy sont  plus faibles que ceux obtenus avec 
# l'accuracy : 0.70 contre 0.79. 

# On peut donc dire que le modèle souffre du déséquilibre de classes.